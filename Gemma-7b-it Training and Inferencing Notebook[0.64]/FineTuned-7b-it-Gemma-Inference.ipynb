{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "959e4c5b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-11T22:38:08.246618Z",
     "iopub.status.busy": "2024-04-11T22:38:08.246174Z",
     "iopub.status.idle": "2024-04-11T22:38:09.548073Z",
     "shell.execute_reply": "2024-04-11T22:38:09.547061Z"
    },
    "papermill": {
     "duration": 1.311489,
     "end_time": "2024-04-11T22:38:09.550651",
     "exception": false,
     "start_time": "2024-04-11T22:38:08.239162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb160bca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T22:38:09.561905Z",
     "iopub.status.busy": "2024-04-11T22:38:09.561422Z",
     "iopub.status.idle": "2024-04-11T22:38:28.551395Z",
     "shell.execute_reply": "2024-04-11T22:38:28.550227Z"
    },
    "papermill": {
     "duration": 18.998296,
     "end_time": "2024-04-11T22:38:28.554137",
     "exception": false,
     "start_time": "2024-04-11T22:38:09.555841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/bitsandbytes2/bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl\r\n",
      "Processing /kaggle/input/bitsandbytes2/bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\r\n",
      "Installing collected packages: bitsandbytes\r\n",
      "Successfully installed bitsandbytes-0.43.0\r\n"
     ]
    }
   ],
   "source": [
    "#For offline installtion this bitsandbytes wheel to be uploaded\n",
    "!pip install bitsandbytes --no-index --find-links=file:///kaggle/input/bitsandbytes2/bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae01fda4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T22:38:28.566022Z",
     "iopub.status.busy": "2024-04-11T22:38:28.565685Z",
     "iopub.status.idle": "2024-04-11T22:39:01.704168Z",
     "shell.execute_reply": "2024-04-11T22:39:01.703003Z"
    },
    "papermill": {
     "duration": 33.147527,
     "end_time": "2024-04-11T22:39:01.706909",
     "exception": false,
     "start_time": "2024-04-11T22:38:28.559382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2481207e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T22:39:01.719665Z",
     "iopub.status.busy": "2024-04-11T22:39:01.719349Z",
     "iopub.status.idle": "2024-04-11T22:39:15.074838Z",
     "shell.execute_reply": "2024-04-11T22:39:15.073678Z"
    },
    "papermill": {
     "duration": 13.364732,
     "end_time": "2024-04-11T22:39:15.077586",
     "exception": false,
     "start_time": "2024-04-11T22:39:01.712854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/peftfile2/peft-0.10.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/peftfile2/peft-0.10.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.39.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\r\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.28.0)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.2)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\r\n",
      "Installing collected packages: peft\r\n",
      "Successfully installed peft-0.10.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install peft --no-index --find-links=file:///kaggle/input/peftfile2/peft-0.10.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e8f757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T22:39:15.092256Z",
     "iopub.status.busy": "2024-04-11T22:39:15.091902Z",
     "iopub.status.idle": "2024-04-11T22:41:58.377241Z",
     "shell.execute_reply": "2024-04-11T22:41:58.376369Z"
    },
    "papermill": {
     "duration": 163.295783,
     "end_time": "2024-04-11T22:41:58.379911",
     "exception": false,
     "start_time": "2024-04-11T22:39:15.084128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb035beeab744ecf8dee81adaa4a613e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading the base model in 4 bit\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    \n",
    "    load_in_4bit=True,bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\",quantization_config=bnb_config, device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f580af8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T22:41:58.396771Z",
     "iopub.status.busy": "2024-04-11T22:41:58.396261Z",
     "iopub.status.idle": "2024-04-11T22:42:13.815469Z",
     "shell.execute_reply": "2024-04-11T22:42:13.814470Z"
    },
    "papermill": {
     "duration": 15.430403,
     "end_time": "2024-04-11T22:42:13.817867",
     "exception": false,
     "start_time": "2024-04-11T22:41:58.387464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Attaching the adapter files\n",
    "peft_model_id = \"/kaggle/input/adaptermodel2/\"\n",
    "model.load_adapter(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f98fc34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T22:42:13.853139Z",
     "iopub.status.busy": "2024-04-11T22:42:13.852567Z",
     "iopub.status.idle": "2024-04-11T22:42:13.868281Z",
     "shell.execute_reply": "2024-04-11T22:42:13.867440Z"
    },
    "papermill": {
     "duration": 0.025101,
     "end_time": "2024-04-11T22:42:13.870130",
     "exception": false,
     "start_time": "2024-04-11T22:42:13.845029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Poost processing to remove any unwanted sequence of words from original and rewritten text. \n",
    "import string\n",
    "import re\n",
    "def new_original(original,text):\n",
    "    answer=text\n",
    "    listt=[\"Hello world\"]\n",
    "    try:\n",
    "        words = original.split()\n",
    "        for i in range(0,len(words)):\n",
    "            if len(words) % 2 == 0:\n",
    "                if i == len(words)-3:\n",
    "                    strr = words[i+1]+\" \"+words[i+2]\n",
    "                    strr = strr.strip()\n",
    "                    if strr in answer:\n",
    "                        listt.append(strr)\n",
    "                        return listt\n",
    "            else:\n",
    "                if i == len(words)-3:\n",
    "                    strr = words[i] +\" \"+words[i+1]+\" \"+words[i+2]\n",
    "                    strr = strr.strip()\n",
    "                    if strr in answer:\n",
    "                        listt.append(strr)\n",
    "                        return listt\n",
    "            strr = words[i] + \" \"+words[i+1]\n",
    "            strr = strr.strip()\n",
    "            if strr in answer:\n",
    "                listt.append(strr)\n",
    "            \n",
    "        return listt\n",
    "    except:\n",
    "        \n",
    "        return listt\n",
    "def new_rewritten(rewritten,text):    \n",
    "    answer=text\n",
    "    listt=[\"Hello world\"]\n",
    "    try:\n",
    "        words = rewritten.split()\n",
    "        for i in range(0,len(words)):\n",
    "            if len(words) % 2 == 0:\n",
    "                if i == len(words)-3:\n",
    "                    strr = words[i+1]+\" \"+words[i+2]\n",
    "                    strr = strr.strip()\n",
    "                    if strr in answer:\n",
    "                        listt.append(strr)\n",
    "                        return listt\n",
    "                    else:\n",
    "                        return listt\n",
    "            else:\n",
    "                if i == len(words)-3:\n",
    "                    strr = words[i] +\" \"+words[i+1]+\" \"+words[i+2]\n",
    "                    strr = strr.strip()\n",
    "                    if strr in answer:\n",
    "                        listt.append(strr)\n",
    "                        return listt\n",
    "                    else:\n",
    "                        return listt\n",
    "            strr = words[i] + \" \"+words[i+1]\n",
    "            strr = strr.strip()\n",
    "            if strr in answer:\n",
    "                listt.append(strr)\n",
    "        return listt\n",
    "    except:\n",
    "        \n",
    "        return listt\n",
    "    \n",
    "def remove_punctuation(text):\n",
    "    try:\n",
    "        pattern = r'[{}]'.format(re.escape(string.punctuation+\".\"))\n",
    "        cleaned_text = re.sub(pattern, ' ', text)\n",
    "        return cleaned_text\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "\n",
    "def remove_double_spaces(text):\n",
    "    try:\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "        return cleaned_text\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e004d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T22:42:13.886137Z",
     "iopub.status.busy": "2024-04-11T22:42:13.885898Z",
     "iopub.status.idle": "2024-04-11T22:42:36.871322Z",
     "shell.execute_reply": "2024-04-11T22:42:36.870450Z"
    },
    "papermill": {
     "duration": 22.995809,
     "end_time": "2024-04-11T22:42:36.873877",
     "exception": false,
     "start_time": "2024-04-11T22:42:13.878068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 22:42:21.454900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-11 22:42:21.455027: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-11 22:42:21.737297: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "test = pd.read_csv(\"/kaggle/input/llm-prompt-recovery/test.csv\")\n",
    "test.reset_index(inplace=True,drop=True)\n",
    "for index,value in enumerate(test['original_text']):\n",
    "    \n",
    "    original = value\n",
    "    rewritten = test.loc[index,'rewritten_text']\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    prompt = f\"\"\"<bos><start_of_turn>user\n",
    "Hello Need Help . My Friend translated my original text into something new .\\nOriginal Text : {original}\\nRewritten Text : {rewritten}\\nMy friend used a large language model to rewrite this . \n",
    "Can you craft a exact single-line prompt which he might have used against my original text to get to the rewritten text.<end_of_turn>\n",
    "<start_of_turn>model Prompt:\"\"\"\n",
    "    \n",
    "    inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=inputs.to(model.device),max_new_tokens=100,temperature=0.7,do_sample=True)\n",
    "    answer = tokenizer.decode(outputs[0])\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        start = answer.find(\"<start_of_turn>model\")\n",
    "        answer = answer[start+20:]\n",
    "        answer = answer.replace(\"Prompt:\",\"\")\n",
    "        answer = answer.replace(\"<eos>\",\"\")\n",
    "    \n",
    "        answer = remove_punctuation(answer)\n",
    "        original = remove_punctuation(original)\n",
    "        rewritten = remove_punctuation(rewritten)\n",
    "        \n",
    "        answer = answer.lower()\n",
    "        original = original.lower()\n",
    "        rewritten = rewritten.lower()\n",
    "        \n",
    "        answer = remove_double_spaces(answer)\n",
    "        original = remove_double_spaces(original)\n",
    "        rewritten = remove_double_spaces(rewritten)\n",
    "        \n",
    "        \n",
    "        finalans = answer\n",
    "        try:\n",
    "            list1 = new_original(original,answer)\n",
    "            list2 = new_rewritten(rewritten,answer)\n",
    "            if len(list2) > len(list1):\n",
    "                if len(list2) != 0:\n",
    "                    for words in list2:\n",
    "                        \n",
    "                        answer = answer.replace(words,\"\")\n",
    "                \n",
    "            elif len(list2) < len(list1):\n",
    "                if len(list1) != 0:\n",
    "                    for words in list1:\n",
    "                        \n",
    "                        answer = answer.replace(words,\"\")\n",
    "                \n",
    "                \n",
    "                \n",
    "        except:\n",
    "            answer = finalans\n",
    "        answer = answer.replace(\".\",\"\")\n",
    "        answer = answer.replace(\"*\",\"\")\n",
    "        answer = answer.replace(\":\",\"\")\n",
    "        answer = answer.replace(\",\",\"\")\n",
    "        answer = answer.replace(\"using a large language model\",\"\")\n",
    "        answer = answer.replace(\"additional requirements\",\"\")\n",
    "        answer = answer.replace(\"additional instructions\",\"\")\n",
    "        answer = answer.replace(\"translated\",\"rewritten\")\n",
    "        answer = answer.replace(\"style of writing\",\" \")\n",
    "        answer = answer.replace(\"use of large language models\",\"\")\n",
    "        answer = answer.replace(\"large language models\",\"\")\n",
    "        answer = answer.replace(\"using a large language model\",\"\")\n",
    "        answer = answer.replace(\"large language model\",\"\")\n",
    "        answer = answer.replace(\"emphasizing\",\"\")\n",
    "        answer = answer.replace(\"revise\",\"reframe\")\n",
    "        answer = answer.replace(\"please ensure that the translation is accurate and captures the essence of the original text\",\"\")\n",
    "        answer = ' '.join([word for word in answer.split() if len(word) > 1]) \n",
    "        if len(answer) == 0:\n",
    "            answer = \"\"\"Please Improve,Rewrite and Rephrase the provided text in a style that adopts the characteristics of the original text, while enhancing the clarity, elegance, and impact. Maintain the core meaning and factual accuracy of the original, and utilize figurative language - including rhyme and playful language where appropriate - creatively to achieve the desired effect aligning with the tone, diction, and stylistic elements of the original text. \"\"\"\n",
    "        answer = answer.strip()   \n",
    "        #mean prompt + llm response\n",
    "        test.loc[index,'rewrite_prompt'] = \"Please improve this text using the writing style with maintaining the original meaning but altering the tone reimagining it through the lens \"+answer\n",
    "    except:\n",
    "        answer = tokenizer.decode(outputs[0])\n",
    "        start = answer.find(\"<start_of_turn>model\")\n",
    "        answer = answer[start+20:]\n",
    "        answer = answer.lower()\n",
    "        answer = answer.replace(\"prompt:\",\"\")\n",
    "        answer = answer.replace(\"<eos>\",\"\")\n",
    "        answer = answer.replace(\"using a large language model\",\"\")\n",
    "        answer = answer.replace(\"additional requirements\",\"\")\n",
    "        answer = answer.replace(\"additional instructions\",\"\")\n",
    "        answer = answer.replace(\"translated\",\"rewritten\")\n",
    "        answer = answer.replace(\"use of large language models\",\"\")\n",
    "        answer = answer.replace(\"large language models\",\"\")\n",
    "        answer = answer.replace(\"using a large language model\",\"\")\n",
    "        answer = answer.replace(\"large language model\",\"\")\n",
    "        answer = answer.replace(\"revise\",\"reframe\")\n",
    "        #mean prompt + llm response\n",
    "        test.loc[index,'rewrite_prompt'] = \"Please improve this text using the writing style with maintaining the original meaning but altering the tone reimagining it through the lens \"+answer\n",
    "\n",
    "        \n",
    "        \n",
    "test = test[['id','rewrite_prompt']]\n",
    "test.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6209569f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T22:42:36.890058Z",
     "iopub.status.busy": "2024-04-11T22:42:36.889734Z",
     "iopub.status.idle": "2024-04-11T22:42:36.895622Z",
     "shell.execute_reply": "2024-04-11T22:42:36.894660Z"
    },
    "papermill": {
     "duration": 0.016239,
     "end_time": "2024-04-11T22:42:36.897662",
     "exception": false,
     "start_time": "2024-04-11T22:42:36.881423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please improve this text using the writing style with maintaining the original meaning but altering the tone reimagining it through the lens convert this into shanty\n"
     ]
    }
   ],
   "source": [
    "print(test.loc[0,'rewrite_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c0554",
   "metadata": {
    "papermill": {
     "duration": 0.006753,
     "end_time": "2024-04-11T22:42:36.911620",
     "exception": false,
     "start_time": "2024-04-11T22:42:36.904867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7806901,
     "sourceId": 67121,
     "sourceType": "competition"
    },
    {
     "datasetId": 4779039,
     "sourceId": 8094357,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4779196,
     "sourceId": 8094576,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4779217,
     "sourceId": 8094601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4779579,
     "sourceId": 8095109,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 8332,
     "sourceId": 28808,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 276.213963,
   "end_time": "2024-04-11T22:42:40.227828",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-11T22:38:04.013865",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0360b8170b9a4b80add858a400fbe142": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "29ca6a65df724c35bd0efdb65699f993": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "43b34e046e6f40ec805fbb26de1c09f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d469ce832ce429186a54880d9c3e9ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98bbf86d14a54f989b22a9ed5c8721ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9d33bdcd6e5d4624b94d7c44ad9efd81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8d469ce832ce429186a54880d9c3e9ce",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0360b8170b9a4b80add858a400fbe142",
       "value": 4
      }
     },
     "a3ccfd4484dd4de288f660e95cc98dd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9a6fe4270cd48689ca03a16e6592de9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a3ccfd4484dd4de288f660e95cc98dd1",
       "placeholder": "​",
       "style": "IPY_MODEL_98bbf86d14a54f989b22a9ed5c8721ce",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "ba6e495a99e24ef89a665b4bbd826960": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_43b34e046e6f40ec805fbb26de1c09f5",
       "placeholder": "​",
       "style": "IPY_MODEL_ded96d08b3424b82bf648aa8b6bae0f2",
       "value": " 4/4 [02:29&lt;00:00, 34.14s/it]"
      }
     },
     "bb035beeab744ecf8dee81adaa4a613e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a9a6fe4270cd48689ca03a16e6592de9",
        "IPY_MODEL_9d33bdcd6e5d4624b94d7c44ad9efd81",
        "IPY_MODEL_ba6e495a99e24ef89a665b4bbd826960"
       ],
       "layout": "IPY_MODEL_29ca6a65df724c35bd0efdb65699f993"
      }
     },
     "ded96d08b3424b82bf648aa8b6bae0f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
